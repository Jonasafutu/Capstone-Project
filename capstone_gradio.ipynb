{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a9rGxPTHm5ss"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install gradio scipy imbalanced-learn mlxtend\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KzfwXtFAm6jI",
        "outputId": "56cc08ca-164f-4e16-a28f-734c509b858e"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting gradio\n",
            "  Downloading gradio-3.43.2-py3-none-any.whl (20.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m20.1/20.1 MB\u001b[0m \u001b[31m44.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (1.11.2)\n",
            "Requirement already satisfied: imbalanced-learn in /usr/local/lib/python3.10/dist-packages (0.10.1)\n",
            "Requirement already satisfied: mlxtend in /usr/local/lib/python3.10/dist-packages (0.22.0)\n",
            "Collecting aiofiles<24.0,>=22.0 (from gradio)\n",
            "  Downloading aiofiles-23.2.1-py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: altair<6.0,>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (4.2.2)\n",
            "Collecting fastapi (from gradio)\n",
            "  Downloading fastapi-0.103.1-py3-none-any.whl (66 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m66.2/66.2 kB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting ffmpy (from gradio)\n",
            "  Downloading ffmpy-0.3.1.tar.gz (5.5 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting gradio-client==0.5.0 (from gradio)\n",
            "  Downloading gradio_client-0.5.0-py3-none-any.whl (298 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m298.2/298.2 kB\u001b[0m \u001b[31m27.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting httpx (from gradio)\n",
            "  Downloading httpx-0.25.0-py3-none-any.whl (75 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.7/75.7 kB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting huggingface-hub>=0.14.0 (from gradio)\n",
            "  Downloading huggingface_hub-0.17.1-py3-none-any.whl (294 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m294.8/294.8 kB\u001b[0m \u001b[31m25.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: importlib-resources<7.0,>=1.3 in /usr/local/lib/python3.10/dist-packages (from gradio) (6.0.1)\n",
            "Requirement already satisfied: jinja2<4.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (3.1.2)\n",
            "Requirement already satisfied: markupsafe~=2.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (2.1.3)\n",
            "Requirement already satisfied: matplotlib~=3.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (3.7.1)\n",
            "Requirement already satisfied: numpy~=1.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (1.23.5)\n",
            "Collecting orjson~=3.0 (from gradio)\n",
            "  Downloading orjson-3.9.7-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (138 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m138.7/138.7 kB\u001b[0m \u001b[31m16.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from gradio) (23.1)\n",
            "Requirement already satisfied: pandas<3.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (1.5.3)\n",
            "Requirement already satisfied: pillow<11.0,>=8.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (9.4.0)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from gradio) (1.10.12)\n",
            "Collecting pydub (from gradio)\n",
            "  Downloading pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n",
            "Collecting python-multipart (from gradio)\n",
            "  Downloading python_multipart-0.0.6-py3-none-any.whl (45 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.7/45.7 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pyyaml<7.0,>=5.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (6.0.1)\n",
            "Requirement already satisfied: requests~=2.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (2.31.0)\n",
            "Collecting semantic-version~=2.0 (from gradio)\n",
            "  Downloading semantic_version-2.10.0-py2.py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: typing-extensions~=4.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (4.5.0)\n",
            "Collecting uvicorn>=0.14.0 (from gradio)\n",
            "  Downloading uvicorn-0.23.2-py3-none-any.whl (59 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m59.5/59.5 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting websockets<12.0,>=10.0 (from gradio)\n",
            "  Downloading websockets-11.0.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (129 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m129.9/129.9 kB\u001b[0m \u001b[31m13.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from gradio-client==0.5.0->gradio) (2023.6.0)\n",
            "Requirement already satisfied: scikit-learn>=1.0.2 in /usr/local/lib/python3.10/dist-packages (from imbalanced-learn) (1.2.2)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from imbalanced-learn) (1.3.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from imbalanced-learn) (3.2.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from mlxtend) (67.7.2)\n",
            "Requirement already satisfied: entrypoints in /usr/local/lib/python3.10/dist-packages (from altair<6.0,>=4.2.0->gradio) (0.4)\n",
            "Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.10/dist-packages (from altair<6.0,>=4.2.0->gradio) (4.19.0)\n",
            "Requirement already satisfied: toolz in /usr/local/lib/python3.10/dist-packages (from altair<6.0,>=4.2.0->gradio) (0.12.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.14.0->gradio) (3.12.2)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.14.0->gradio) (4.66.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (1.1.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (0.11.0)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (4.42.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (1.4.5)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (3.1.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas<3.0,>=1.0->gradio) (2023.3.post1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests~=2.0->gradio) (3.2.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests~=2.0->gradio) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests~=2.0->gradio) (2.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests~=2.0->gradio) (2023.7.22)\n",
            "Requirement already satisfied: click>=7.0 in /usr/local/lib/python3.10/dist-packages (from uvicorn>=0.14.0->gradio) (8.1.7)\n",
            "Collecting h11>=0.8 (from uvicorn>=0.14.0->gradio)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: anyio<4.0.0,>=3.7.1 in /usr/local/lib/python3.10/dist-packages (from fastapi->gradio) (3.7.1)\n",
            "Collecting starlette<0.28.0,>=0.27.0 (from fastapi->gradio)\n",
            "  Downloading starlette-0.27.0-py3-none-any.whl (66 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.0/67.0 kB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting httpcore<0.19.0,>=0.18.0 (from httpx->gradio)\n",
            "  Downloading httpcore-0.18.0-py3-none-any.whl (76 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.0/76.0 kB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx->gradio) (1.3.0)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<4.0.0,>=3.7.1->fastapi->gradio) (1.1.3)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio) (23.1.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio) (2023.7.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio) (0.30.2)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio) (0.10.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib~=3.0->gradio) (1.16.0)\n",
            "Building wheels for collected packages: ffmpy\n",
            "  Building wheel for ffmpy (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for ffmpy: filename=ffmpy-0.3.1-py3-none-any.whl size=5579 sha256=f7da435e0c223d0ec0a22ebf366b45c4ad28c056eefdb5c5f316dccdf31df602\n",
            "  Stored in directory: /root/.cache/pip/wheels/01/a6/d1/1c0828c304a4283b2c1639a09ad86f83d7c487ef34c6b4a1bf\n",
            "Successfully built ffmpy\n",
            "Installing collected packages: pydub, ffmpy, websockets, semantic-version, python-multipart, orjson, h11, aiofiles, uvicorn, starlette, huggingface-hub, httpcore, httpx, fastapi, gradio-client, gradio\n",
            "Successfully installed aiofiles-23.2.1 fastapi-0.103.1 ffmpy-0.3.1 gradio-3.43.2 gradio-client-0.5.0 h11-0.14.0 httpcore-0.18.0 httpx-0.25.0 huggingface-hub-0.17.1 orjson-3.9.7 pydub-0.25.1 python-multipart-0.0.6 semantic-version-2.10.0 starlette-0.27.0 uvicorn-0.23.2 websockets-11.0.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "es9LdgWwnYXD",
        "outputId": "266d1a6d-5136-4c52-c3f7-72422b943e0a"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd"
      ],
      "metadata": {
        "id": "hURBr8PFozak"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "path = \"/content/drive/MyDrive/Capstone Project /\"\n",
        "\n",
        "test = pd.read_csv(path + 'Test.csv')\n",
        "sample_submission = pd.read_csv(path + 'SampleSubmission.csv')\n",
        "train = pd.read_csv(path + 'Train.csv')\n",
        "variable_definitions = pd.read_csv(path + 'VariableDefinitions.csv')"
      ],
      "metadata": {
        "id": "fU1Zo5O-no2l"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# -*- coding: utf-8 -*-\n",
        "\"\"\"Elly 2.ipynb\n",
        "\n",
        "Automatically generated by Colaboratory.\n",
        "\n",
        "Original file is located at\n",
        "    https://colab.research.google.com/drive/1WFSE8UyWKXZ9AZv81U-QaCWLTxe8I5kn\n",
        "\"\"\"\n",
        "\n",
        "# Commented out IPython magic to ensure Python compatibility.\n",
        "# Data Manipuulation\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Vizualisation (Matplotlib, Plotly, Seaborn, etc. )\n",
        "# %matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import plotly.graph_objects as go\n",
        "import plotly.express as px\n",
        "import ipywidgets as widgets\n",
        "from IPython.display import display\n",
        "\n",
        "# Feature Processing (Scikit-learn processing, etc. )\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.metrics import confusion_matrix , classification_report, f1_score, accuracy_score,precision_score, recall_score, fbeta_score, make_scorer, roc_auc_score\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "\n",
        "from sklearn.model_selection import GridSearchCV, cross_validate\n",
        "\n",
        "from sklearn.model_selection import cross_val_score, cross_val_predict\n",
        "from sklearn.metrics import roc_auc_score,roc_curve\n",
        "\n",
        "#from skopt import BayesSearchCV\n",
        "from sklearn.utils import class_weight\n",
        "\n",
        "import scipy.stats as stats\n",
        "\n",
        "# models\n",
        "from sklearn import svm\n",
        "#from xgboost import XGBClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "from xgboost import XGBClassifier\n",
        "\n",
        "\n",
        "from imblearn.over_sampling import  RandomOverSampler\n",
        "from mlxtend.feature_selection import SequentialFeatureSelector as SFS\n",
        "from sklearn.model_selection import KFold, StratifiedKFold, RepeatedStratifiedKFold\n",
        "\n",
        "\n",
        "# model interpretation\n",
        "#import shap\n",
        "import joblib\n",
        "import os\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "# Load the Train dataset\n",
        "#train = pd.read_csv('C:\\Users\\user\\Desktop\\ChurnAnalysis_CapstonePred\\Train.csv')\n",
        "#test = pd.read_csv('C:\\Users\\user\\Desktop\\ChurnAnalysis_CapstonePred\\Test.csv')\n",
        "\n",
        "\n",
        "# create a functioon to replace the missing values with mean for each respective column in the train data\n",
        "columns_to_fill = ['MONTANT', 'FREQUENCE_RECH', 'REVENUE', 'ARPU_SEGMENT',\n",
        "                   'FREQUENCE', 'DATA_VOLUME', 'ON_NET', 'ORANGE', 'TIGO',\n",
        "                   'FREQ_TOP_PACK']\n",
        "\n",
        "for column in columns_to_fill:\n",
        "    train[column].fillna(train[column].mean(), inplace=True)\n",
        "\n",
        "# create a functioon to replace the missing values with mean for each respective column in the test data\n",
        "columns_to_fill = ['MONTANT', 'FREQUENCE_RECH', 'REVENUE', 'ARPU_SEGMENT',\n",
        "                   'FREQUENCE', 'DATA_VOLUME', 'ON_NET', 'ORANGE', 'TIGO',\n",
        "                   'FREQ_TOP_PACK']\n",
        "\n",
        "for column in columns_to_fill:\n",
        "    test[column].fillna(test[column].mean(), inplace=True)\n",
        "\n",
        "# Create a DataFrame for the train data\n",
        "train = pd.DataFrame(train)\n",
        "\n",
        "# Fill missing values based on the frequency distribution in the train data\n",
        "def fill_missing_with_distribution(column):\n",
        "    freq_distribution = column.value_counts(normalize=True)\n",
        "    missing_count = column.isnull().sum()\n",
        "    missing_indices = column[column.isnull()].index\n",
        "    imputed_values = np.random.choice(freq_distribution.index, size=missing_count, p=freq_distribution.values)\n",
        "    column[missing_indices] = imputed_values\n",
        "\n",
        "# Perform missing value imputation for each categorical column in the train data\n",
        "categorical_columns = ['REGION', 'TOP_PACK']\n",
        "\n",
        "for col in categorical_columns:\n",
        "    fill_missing_with_distribution(train[col])\n",
        "\n",
        "# Create a DataFrame for the test data\n",
        "test = pd.DataFrame(test)\n",
        "\n",
        "# Fill missing values based on the frequency distribution in the test data\n",
        "def fill_missing_with_distribution(column):\n",
        "    freq_distribution = column.value_counts(normalize=True)\n",
        "    missing_count = column.isnull().sum()\n",
        "    missing_indices = column[column.isnull()].index\n",
        "    imputed_values = np.random.choice(freq_distribution.index, size=missing_count, p=freq_distribution.values)\n",
        "    column[missing_indices] = imputed_values\n",
        "\n",
        "# Perform missing value imputation for each categorical column\n",
        "categorical_columns_test = ['REGION', 'TOP_PACK']\n",
        "\n",
        "for col in categorical_columns_test:\n",
        "    fill_missing_with_distribution(test[col])\n",
        "\n",
        "\n",
        "\n",
        "train['ZONE1'].fillna((train['ZONE1'].mean()), inplace=True)\n",
        "train['ZONE2'].fillna((train['ZONE2'].mean()), inplace=True)\n",
        "\n",
        "# train.drop(columns=['REGION', 'MRG', 'TOP_PACK'], inplace=True) #drop these columns\n",
        "\n",
        "# **Machine Learning**\n",
        "\n",
        "from sklearn.model_selection import train_test_split,cross_val_score\n",
        "from sklearn.metrics import accuracy_score,confusion_matrix,recall_score,precision_recall_curve, f1_score\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "\"\"\"## **Feature Engineering**\n",
        "\n",
        "### **Feature Selection**\n",
        "\"\"\"\n",
        "\n",
        "drop =['user_id', 'CHURN', 'REGION', 'MRG', 'TOP_PACK']\n",
        "y=train['CHURN']\n",
        "x=train.drop(columns=drop, axis=1)\n",
        "X_train,X_test,y_train,y_test = train_test_split(x,y,test_size = 0.2)\n",
        "\n",
        "print(X_train.shape)\n",
        "print(y_train.shape)\n",
        "\n",
        "\"\"\"### **Splitting Dataset**\"\"\"\n",
        "\n",
        "X_train,X_val,y_train,y_val = train_test_split(X_train,y_train,test_size = 0.3, random_state=1)\n",
        "\n",
        "xt= X_train\n",
        "yt= y_train\n",
        "\n",
        "\"\"\"### **Standize Numeric Columns**\"\"\"\n",
        "\n",
        "num_cols = ['MONTANT', 'FREQUENCE_RECH', 'REVENUE', 'ARPU_SEGMENT', 'FREQUENCE',\n",
        "       'DATA_VOLUME', 'ON_NET', 'ORANGE', 'TIGO',\n",
        "       'REGULARITY', 'FREQ_TOP_PACK']\n",
        "      #  'ZONE1', 'ZONE2',\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_train[num_cols] = scaler.fit_transform(X_train[num_cols])\n",
        "X_train.head()\n",
        "X_test[num_cols] = scaler.transform(X_test[num_cols])\n",
        "X_val[num_cols] = scaler.transform(X_val[num_cols])\n",
        "\n",
        "\"\"\"### **Encode the Tenure Column**\"\"\"\n",
        "\n",
        "encoder = LabelEncoder()\n",
        "X_train[\"TENURE\"] = encoder.fit_transform(X_train[\"TENURE\"])\n",
        "X_test[\"TENURE\"] = encoder.transform(X_test[\"TENURE\"])\n",
        "X_val['TENURE'] = encoder.transform(X_val[\"TENURE\"])\n",
        "\n",
        "# Due to high number of missing data in Zone 1 and Zone 2 their column would be dropped\n",
        "\n",
        "X_train.drop(columns=['ZONE1', 'ZONE2'], inplace=True)\n",
        "X_test.drop(columns=['ZONE1', 'ZONE2'], inplace=True)\n",
        "X_val.drop(columns=['ZONE1', 'ZONE2'], inplace=True)\n",
        "\n",
        "\"\"\"### **Balancing Dataset**\"\"\"\n",
        "\n",
        "x_train_randOverSample = X_train.copy()\n",
        "y_train_randOverSample = y_train.copy()\n",
        "\n",
        "\n",
        "randOverSample = RandomOverSampler(random_state=100,)\n",
        "X_train_randOverSample, y_train_randOverSample = randOverSample.fit_resample(x_train_randOverSample, y_train_randOverSample.ravel())\n",
        "\n",
        "\n",
        "\"\"\"## Creating Models\"\"\"\n",
        "\n",
        "last_models_metrics = []\n",
        "\n",
        "classifiers = [('LR', LogisticRegression()),\n",
        "                   (\"DT\", DecisionTreeClassifier()),\n",
        "                   (\"RF\", RandomForestClassifier()),\n",
        "                   ('GBM', GradientBoostingClassifier()),\n",
        "                   ('XGBoost', XGBClassifier(use_label_encoder=False, eval_metric='logloss')),\n",
        "\n",
        "                   ]\n",
        "for name, classifier in classifiers:\n",
        "        cv_results = cross_validate(classifier, X_train_randOverSample, y_train_randOverSample, cv=3, scoring=[\"accuracy\", \"f1\", \"roc_auc\", \"precision\", \"recall\"])\n",
        "        accuracy = round(cv_results['test_accuracy'].mean(), 4)\n",
        "        auc = round(cv_results['test_roc_auc'].mean(), 4)\n",
        "        recall = round(cv_results['test_recall'].mean(), 4)\n",
        "        precision = round(cv_results['test_precision'].mean(), 4)\n",
        "        f1 = round(cv_results['test_f1'].mean(), 4)\n",
        "\n",
        "        last_models_metrics.append({\n",
        "        \"Model\": name,\n",
        "        \"Accuracy\": accuracy,\n",
        "        \"AUC\": auc,\n",
        "        \"Recall\": recall,\n",
        "        \"Precision\": precision,\n",
        "        \"F1\": f1\n",
        "          })\n",
        "\n",
        "metrics = {\n",
        "    \"Model\": [\"LR\", \"DT\", \"RF\", \"LightGBM\", \"XGB\", ],\n",
        "    \"Accuracy\": [last_models_metrics[0]['Accuracy'], last_models_metrics[1]['Accuracy'],\n",
        "                 last_models_metrics[2]['Accuracy'], last_models_metrics[3]['Accuracy'],\n",
        "                 last_models_metrics[4]['Accuracy'], ],\n",
        "    \"AUC\": [last_models_metrics[0]['AUC'], last_models_metrics[1]['AUC'],\n",
        "            last_models_metrics[2]['AUC'], last_models_metrics[3]['AUC'],\n",
        "            last_models_metrics[4]['AUC'], ],\n",
        "    \"Recall\": [last_models_metrics[0]['Recall'], last_models_metrics[1]['Recall'],\n",
        "               last_models_metrics[2]['Recall'], last_models_metrics[3]['Recall'],\n",
        "               last_models_metrics[4]['Recall'],],\n",
        "    \"Precision\": [last_models_metrics[0]['Precision'], last_models_metrics[1]['Precision'],\n",
        "                  last_models_metrics[2]['Precision'], last_models_metrics[3]['Precision'],\n",
        "                  last_models_metrics[4]['Precision'],],\n",
        "    \"F1\": [last_models_metrics[0]['F1'], last_models_metrics[1]['F1'],\n",
        "           last_models_metrics[2]['F1'], last_models_metrics[3]['F1'],\n",
        "           last_models_metrics[4]['F1'], ]\n",
        "}\n",
        "\n",
        "\"\"\"### **Feature Importance**\"\"\"\n",
        "\n",
        "models = [RandomForestClassifier(),\n",
        "              XGBClassifier(),\n",
        "            DecisionTreeClassifier()\n",
        "]\n",
        "\n",
        "\n",
        "\"\"\"### **Hyperparameter Optimization**\"\"\"\n",
        "\n",
        "lr_params = {\"C\": [0.001, 0.01, 0.1, 1, 10 ]}\n",
        "knn_params = {\"n_neighbors\": [3, 5]}\n",
        "dt_params = {\"max_depth\": [3, 5, 7]}\n",
        "rf_params = {\"n_estimators\": [10]}\n",
        "xgb_params = {\"learning_rate\": [0.01, 0.1], \"max_depth\": [3]}\n",
        "\n",
        "classifiers = [\n",
        "    (\"LR\", LogisticRegression(), lr_params),\n",
        "\n",
        "    (\"DT\", DecisionTreeClassifier(), dt_params),\n",
        "    (\"RF\", RandomForestClassifier(), rf_params),\n",
        "     (\"XGB\", XGBClassifier(), xgb_params)\n",
        "    ]\n",
        "\n",
        "def hyperparameters_optimization(X_train_randOverSample, y_train_randOverSample, cv=5, scoring=\"f1\"):\n",
        "    print(\"Hyperparameter Optimimization\")\n",
        "    best_models = {}\n",
        "    for name, classifier, params in classifiers:\n",
        "\n",
        "        gs_best = GridSearchCV(classifier, params, cv=cv, n_jobs=-1, verbose=False).fit(X_train_randOverSample,y_train_randOverSample)\n",
        "        final_model = classifier.set_params(**gs_best.best_params_)\n",
        "\n",
        "        cv_results = cross_validate(final_model, X_train_randOverSample, y_train_randOverSample, cv=cv, scoring=scoring)\n",
        "        print(f\"{scoring} (After) : {round(cv_results['test_score'].mean(), 4)}\")\n",
        "        print(f\"{name} best params: {gs_best.best_params_}\", end=\"\\n\\n\")\n",
        "        best_models[name] = final_model\n",
        "    return best_models\n",
        "\n",
        "best_models = hyperparameters_optimization(X_train_randOverSample, y_train_randOverSample)\n",
        "\n",
        "\"\"\"### **Final Model**\n",
        "\n",
        "Based on the above result ,Random Forest would be selected as the final model\n",
        "\"\"\"\n",
        "\n",
        "best_models['RF']\n",
        "\n",
        "RF_model = best_models['RF'].fit(X_train_randOverSample, y_train_randOverSample)\n",
        "\n",
        "# Prediction with Trained Model\n",
        "\n",
        "y_pred = RF_model.predict(X_test)\n",
        "y_prob = RF_model.predict_proba(X_test)[:, 1]\n",
        "#print(classification_report(y_test, y_pred))\n",
        "\n",
        "RF_roc_auc = roc_auc_score(y_test, y_prob)\n",
        "#fpr, tpr, thresholds = roc_curve(y_test, y_prob)\n",
        "#plt.figure()\n",
        "\n",
        "# plt.plot([0,1],[0,1],'r--')\n",
        "# plt.plot(fpr, tpr, marker='.', label='RF')\n",
        "# plt.xlabel('False Positive Rate')\n",
        "# plt.ylabel('True Positive Rate')\n",
        "# plt.title(\"Random Forest ROC\")\n",
        "# plt.legend()\n",
        "# plt.show()\n",
        "\n",
        "\"\"\"### **Saving Model**\"\"\"\n",
        "\n",
        "joblib.dump(best_models['RF'], 'best_model_filename.pkl')\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "29p8tg-Zm6mM",
        "outputId": "6e3ee49e-5155-490b-abad-2b5d336aedf5"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(861619, 14)\n",
            "(861619,)\n",
            "Hyperparameter Optimimization\n",
            "########## LR #########\n",
            "f1 (After) : 0.8324\n",
            "LR best params: {'C': 1}\n",
            "\n",
            "########## DT #########\n",
            "f1 (After) : 0.8338\n",
            "DT best params: {'max_depth': 7}\n",
            "\n",
            "########## RF #########\n",
            "f1 (After) : 0.9051\n",
            "RF best params: {'n_estimators': 10}\n",
            "\n",
            "########## XGB #########\n",
            "f1 (After) : 0.8333\n",
            "XGB best params: {'learning_rate': 0.1, 'max_depth': 3}\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['best_model_filename.pkl']"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_test.head(2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 112
        },
        "id": "WYFntIxco6qu",
        "outputId": "fc012bcf-2e24-4610-81aa-f27af2493764"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "        TENURE   MONTANT  FREQUENCE_RECH   REVENUE  ARPU_SEGMENT  FREQUENCE  \\\n",
              "713703       7  0.000678        0.001120  0.000570      0.000569   0.000607   \n",
              "622779       7  0.922294        1.450304  0.967845      0.967844   1.591502   \n",
              "\n",
              "        DATA_VOLUME    ON_NET    ORANGE      TIGO  REGULARITY  FREQ_TOP_PACK  \n",
              "713703      0.00188  0.001649  0.000787  0.000804   -1.122767       0.000370  \n",
              "622779      0.04830 -0.394595 -0.149192 -0.277542    1.480458       0.507414  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-30f25f3e-3901-40ab-b45f-fbaa6f9b6ddf\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>TENURE</th>\n",
              "      <th>MONTANT</th>\n",
              "      <th>FREQUENCE_RECH</th>\n",
              "      <th>REVENUE</th>\n",
              "      <th>ARPU_SEGMENT</th>\n",
              "      <th>FREQUENCE</th>\n",
              "      <th>DATA_VOLUME</th>\n",
              "      <th>ON_NET</th>\n",
              "      <th>ORANGE</th>\n",
              "      <th>TIGO</th>\n",
              "      <th>REGULARITY</th>\n",
              "      <th>FREQ_TOP_PACK</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>713703</th>\n",
              "      <td>7</td>\n",
              "      <td>0.000678</td>\n",
              "      <td>0.001120</td>\n",
              "      <td>0.000570</td>\n",
              "      <td>0.000569</td>\n",
              "      <td>0.000607</td>\n",
              "      <td>0.00188</td>\n",
              "      <td>0.001649</td>\n",
              "      <td>0.000787</td>\n",
              "      <td>0.000804</td>\n",
              "      <td>-1.122767</td>\n",
              "      <td>0.000370</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>622779</th>\n",
              "      <td>7</td>\n",
              "      <td>0.922294</td>\n",
              "      <td>1.450304</td>\n",
              "      <td>0.967845</td>\n",
              "      <td>0.967844</td>\n",
              "      <td>1.591502</td>\n",
              "      <td>0.04830</td>\n",
              "      <td>-0.394595</td>\n",
              "      <td>-0.149192</td>\n",
              "      <td>-0.277542</td>\n",
              "      <td>1.480458</td>\n",
              "      <td>0.507414</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-30f25f3e-3901-40ab-b45f-fbaa6f9b6ddf')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-30f25f3e-3901-40ab-b45f-fbaa6f9b6ddf button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-30f25f3e-3901-40ab-b45f-fbaa6f9b6ddf');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-c1f00e3f-14d5-48a6-9068-0bb48dd4174c\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-c1f00e3f-14d5-48a6-9068-0bb48dd4174c')\"\n",
              "            title=\"Suggest charts.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-c1f00e3f-14d5-48a6-9068-0bb48dd4174c button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Check if the model works"
      ],
      "metadata": {
        "id": "fpw-7UNuQwC6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "MODEL = best_models['RF']"
      ],
      "metadata": {
        "id": "IU3MGXc3QVaQ"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Predictions using the trained model\n",
        "pred = MODEL.predict(X_test)\n",
        "\n",
        "pred[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nmTwkwE8ps8E",
        "outputId": "9d4bb4a3-012b-4085-90f5-b79d6f3c7d85"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "albDha0BRWzl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Gradio Build"
      ],
      "metadata": {
        "id": "Ts8_Jp9qRXAE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import gradio as gr\n",
        "import pandas as pd\n",
        "\n",
        "# Define a function to classify the output\n",
        "def classifier_1(result):\n",
        "    if result == 0:\n",
        "        return \"Customer will churn\"\n",
        "    else:\n",
        "        return \"Customer will not churn\"\n",
        "\n",
        "# Map numerical values to labels\n",
        "tenure_labels = {\n",
        "    0: \"3-6 months\",\n",
        "    1: \"6-9 months\",\n",
        "    2: \"9-12 months\",\n",
        "    3: \"12-15 months\",\n",
        "    4: \"15-18 months\",\n",
        "    5: \"18-21 months\",\n",
        "    6: \"21-24 months\",\n",
        "    7: \"> 24 months\"\n",
        "}\n",
        "\n",
        "# Reverse the mapping for predictions\n",
        "tenure_values = {v: k for k, v in tenure_labels.items()}\n",
        "\n",
        "def predict(tenure, montant, freq_rech, revenue, arpu, freq, data_vol, on_net, orange, tigo, zone1, zone2, regularity, freq_top_pack):\n",
        "    inputs = [tenure, montant, freq_rech, revenue, arpu, freq, data_vol, on_net, orange, tigo, zone1, zone2, regularity, freq_top_pack]\n",
        "\n",
        "    input_df = pd.DataFrame([inputs], columns=['tenure', 'montant', 'freq_rech', 'revenue', 'arpu',\n",
        "                                               'freq', 'data_vol', 'on_net', 'orange', 'tigo',\n",
        "                                               'zone1', 'zone2', 'regularity', 'freq_top_pack'])\n",
        "    # Convert dropdown label to numerical value\n",
        "    tenure_value = tenure_values[tenure]\n",
        "\n",
        "    pred = MODEL.predict(input_df)\n",
        "\n",
        "    output = classifier_1(pred[0])\n",
        "\n",
        "    # if output == \"Customer will churn\":\n",
        "    #     return [(0, output)]\n",
        "    # else:\n",
        "    #     return [(1, output)]\n",
        "\n",
        "    if output == \"Customer will churn\":\n",
        "        return {\"prediction\": output}\n",
        "    else:\n",
        "        return {\"prediction\": output}\n",
        "\n",
        "# Define the outputs\n",
        "output = gr.outputs.HighlightedText(color_map={\n",
        "    \"Customer will churn\": \"green\",\n",
        "    \"Customer will not churn\": \"red\"\n",
        "})\n",
        "\n",
        "# Create a dropdown menu with labels\n",
        "tenure_dropdown = gr.inputs.Dropdown(list(tenure_labels.values()), label=\"TENURE\")\n",
        "\n",
        "iface = gr.Interface(\n",
        "    fn=predict,\n",
        "    inputs=[\n",
        "        tenure_dropdown,  # Dropdown instead of slider\n",
        "        #gr.inputs.Slider(minimum=1, maximum=7, label=\"TENURE\"),\n",
        "        gr.inputs.Slider(minimum=20, maximum=470000, label=\"MONTANT\"),\n",
        "        gr.inputs.Slider(minimum=1, maximum=131, label=\"FREQUENCE_RECH\"),\n",
        "        gr.inputs.Slider(minimum=1, maximum=530000, label=\"REVENUE\"),\n",
        "        gr.inputs.Slider(minimum=0, maximum=2453, label=\"ARPU_SEGMENT\"),\n",
        "        gr.inputs.Slider(minimum=1, maximum=91, label=\"FREQUENCE\"),\n",
        "        gr.inputs.Slider(minimum=1, maximum=1702309, label=\"DATA_VOLUME\"),\n",
        "        gr.inputs.Slider(minimum=0, maximum=51000, label=\"ON_NET\"),\n",
        "        gr.inputs.Slider(minimum=0, maximum=12040, label=\"ORANGE\"),\n",
        "        gr.inputs.Slider(minimum=0, maximum=4174, label=\"TIGO\"),\n",
        "        #gr.inputs.Slider(minimum=0, maximum=2510, label=\"ZONE1\"),\n",
        "        #gr.inputs.Slider(minimum=0, maximum=3697, label=\"ZONE2\"),\n",
        "        gr.inputs.Slider(minimum=0, maximum=62, label=\"REGULARITY\"),\n",
        "        gr.inputs.Slider(minimum=0, maximum=624, label=\"FREQ_TOP_PACK\")\n",
        "    ],\n",
        "    outputs=output,\n",
        "    title=\"Team Paris Customer Churn Prediction App\",\n",
        "    description=\"Let's Get Started With Some Predictions!\"\n",
        ")\n",
        "\n",
        "iface.launch()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 621
        },
        "id": "5SkaWb6RRZ3i",
        "outputId": "c686baee-fb96-4cf1-e008-ceee011ec160"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "Note: opening Chrome Inspector may crash demo inside Colab notebooks.\n",
            "\n",
            "To create a public link, set `share=True` in `launch()`.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "(async (port, path, width, height, cache, element) => {\n",
              "                        if (!google.colab.kernel.accessAllowed && !cache) {\n",
              "                            return;\n",
              "                        }\n",
              "                        element.appendChild(document.createTextNode(''));\n",
              "                        const url = await google.colab.kernel.proxyPort(port, {cache});\n",
              "\n",
              "                        const external_link = document.createElement('div');\n",
              "                        external_link.innerHTML = `\n",
              "                            <div style=\"font-family: monospace; margin-bottom: 0.5rem\">\n",
              "                                Running on <a href=${new URL(path, url).toString()} target=\"_blank\">\n",
              "                                    https://localhost:${port}${path}\n",
              "                                </a>\n",
              "                            </div>\n",
              "                        `;\n",
              "                        element.appendChild(external_link);\n",
              "\n",
              "                        const iframe = document.createElement('iframe');\n",
              "                        iframe.src = new URL(path, url).toString();\n",
              "                        iframe.height = height;\n",
              "                        iframe.allow = \"autoplay; camera; microphone; clipboard-read; clipboard-write;\"\n",
              "                        iframe.width = width;\n",
              "                        iframe.style.border = 0;\n",
              "                        element.appendChild(iframe);\n",
              "                    })(7865, \"/\", \"100%\", 500, false, window.element)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Ia0pOjLxRdqx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "i3bmV8-IRd5t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "5sNawztlReBg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "kl8E75DUReSK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "kOAWiEayRbL0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Into pipeline"
      ],
      "metadata": {
        "id": "twqCbs6fptdQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import the necessary libraries\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "from sklearn.impute import SimpleImputer\n",
        "from imblearn.over_sampling import RandomOverSampler\n",
        "from sklearn.preprocessing import FunctionTransformer\n",
        "import joblib\n",
        "\n",
        "# Define a preprocessing pipeline\n",
        "preprocessing_pipeline = Pipeline([\n",
        "    ('imputer', SimpleImputer(strategy='mean')),  # Fill missing values with mean\n",
        "    ('scaler', StandardScaler()),  # Standardize numeric columns\n",
        "    ('encoder', LabelEncoder()),  # Encode the TENURE column\n",
        "    ('column_dropper', FunctionTransformer(lambda data: data.drop(columns=['ZONE1', 'ZONE2'], axis=1), validate=False)),  # Drop specified columns\n",
        "    ('oversampler', RandomOverSampler(random_state=100)),  # Balance the dataset\n",
        "])\n",
        "\n",
        "# Define the final model (Random Forest)\n",
        "final_model = RandomForestClassifier()\n",
        "\n",
        "# Create a full pipeline by combining preprocessing and the final model\n",
        "full_pipeline = Pipeline([\n",
        "    ('preprocessing', preprocessing_pipeline),\n",
        "    ('model', final_model),\n",
        "])\n",
        "\n",
        "# Fit the full pipeline to your training data\n",
        "X_train_randOverSample, y_train_randOverSample = preprocessing_pipeline.fit(X_train, y_train) #_resample\n",
        "full_pipeline.fit(X_train_randOverSample, y_train_randOverSample)\n",
        "\n",
        "# Save the entire pipeline, including preprocessing and the final model\n",
        "joblib.dump(full_pipeline, 'full_pipeline_with_columns_dropped.pkl')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 408
        },
        "id": "d1PgKJZbpwoi",
        "outputId": "b1ec0de9-1d80-4da8-d84c-c84ce09fb251"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-13-e10a3d592c4b>\u001b[0m in \u001b[0;36m<cell line: 29>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;31m# Fit the full pipeline to your training data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m \u001b[0mX_train_randOverSample\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train_randOverSample\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpreprocessing_pipeline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#_resample\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m \u001b[0mfull_pipeline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train_randOverSample\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train_randOverSample\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m    399\u001b[0m         \"\"\"\n\u001b[1;32m    400\u001b[0m         \u001b[0mfit_params_steps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_fit_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 401\u001b[0;31m         \u001b[0mXt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params_steps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    402\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0m_print_elapsed_time\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Pipeline\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_log_message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    403\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_final_estimator\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m\"passthrough\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py\u001b[0m in \u001b[0;36m_fit\u001b[0;34m(self, X, y, **fit_params_steps)\u001b[0m\n\u001b[1;32m    357\u001b[0m                 \u001b[0mcloned_transformer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtransformer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    358\u001b[0m             \u001b[0;31m# Fit or load from cache the current transformer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 359\u001b[0;31m             X, fitted_transformer = fit_transform_one_cached(\n\u001b[0m\u001b[1;32m    360\u001b[0m                 \u001b[0mcloned_transformer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    361\u001b[0m                 \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/joblib/memory.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    351\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    352\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 353\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    354\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    355\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcall_and_shelve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py\u001b[0m in \u001b[0;36m_fit_transform_one\u001b[0;34m(transformer, X, y, weight, message_clsname, message, **fit_params)\u001b[0m\n\u001b[1;32m    891\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0m_print_elapsed_time\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage_clsname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    892\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtransformer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"fit_transform\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 893\u001b[0;31m             \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtransformer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    894\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    895\u001b[0m             \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtransformer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/utils/_set_output.py\u001b[0m in \u001b[0;36mwrapped\u001b[0;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[1;32m    138\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mwraps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwrapped\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 140\u001b[0;31m         \u001b[0mdata_to_wrap\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    141\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_to_wrap\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    142\u001b[0m             \u001b[0;31m# only wrap the first output for cross decomposition\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: LabelEncoder.fit_transform() takes 2 positional arguments but 3 were given"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "KEWdvsgdyQLt"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}